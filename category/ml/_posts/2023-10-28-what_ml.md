---
layout: post
title: 딥러닝이란?
subtitle: 딥러닝이란 무엇인가?
author: MinJun Ju
comments: true 
toc: true
tags: [ml, ai, deep learning, supervised training]
categories: ml
cover-img: /assets/post_img/background/CocoaPod-bg.png
thumbnail-img: /assets/post_img/background/CocoaPod-bg.png
share-img: /assets/post_img/background/CocoaPod-bg.png
---

[케라스 창시자에게 배우는 딥러닝 2판](https://github.com/gilbutITbook/080315) 을 참고 하였습니다.

---

- 보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동 입니다.
- 머신 러닝 시스템은 명시적으로 프로그램되는 것이 아니라 훈련(training) 됩니다. 
- 알고리즘의 성능을 측정하는 방법: 알고리즘의 현재 출력과 기대 출력 간의 차이를 결정하기 위해서 필요합니다. 측정값은 알고리즘의 작동방식을 교정하기 위한 신호로 다시 피드백 됩니다. 이런 수정 단계를 **학습(learning)** 라고 합니다.
- 머신 러닝 모델은 입력 데이터를 의미 있는 출력으로 변환합니다. 이것이 입력과 출력으로 구성된 샘플로부터 학습하는 과정입니다. 그렇기 때문에 머신 러닝과 딥러닝의 핵심 문제는 의미 있게 데이터를 변환하는 것입니다. **다른 말로 하자면 기대 출력에 가까워지도록 입력 데이터의 유용한 표현(representation)을 학습 하는 것입니다.**
- 딥러닝은 머신 러닝에서 가장 중요한 단계인 특성 공학을 완전히 자동화하기 때문에 문제를 더 해결하기 쉽게 만들어 줍니다. 
- 일반화의 원천인 보간: 다루는 데이터 포인트를 보간할 수 있다면 이전에 본 적 없는 포인트를 해당 매니폴드에서 가까이 놓인 다른 포이늩와 연결하여 이해할 수 있습니다. **다른 말로 하면 공간 안의 샘플만 사용해서 공간 전체를 이해할 수 있습니다. 보간을 사용해서 빈 곳을 채울 수 있기 때문입니다. **
- 정확한 일반화가 가능한 모델을 훈련하기 위해서는 입력 공간의 조밀한 샘플링이 필수적이다. 
- 데이터셋으로 작업을 시작하기 전에 항상 넘어야 할 간단한 상식 수준의 기준점을 정해야 합니다. 이 임계 값을 넘으면 제대로 하고 있음을 알 수 있습니다. 모델이 실제 입력 데이터에 있는 정보를 사용하여 일반화되는 예측을 만들고 있으므로 계속 진행할 수 있습니다. 


---

## 훈련 성능 향상하기

- 최적적합 모델을 얻으려면 먼저 과대적합되어야 합니다. 이 경계가 어디인지 미리 알지 못하기 때문에 경계를 찾으려면 넘어가 보아야 합니다. 따라서 문제를 다루기 시작할 때 초기 목표는 약간의 일반화 능력을 보이고 과대적합할 수 있는 모델을 얻는 것입니다. 
- 구조에 대해 더 나은 가정하기: 일반화를 달성하려면 문제에 대한 올바른 가정을 하는 모델을 사용해야 합니다. 즉, 구조에 대한 올바른 가정을 내려야 합니다. 


---

## 일반화 성능 향상하기

- 주어진 문제에 지나치게 잡음이 많거나 리스트 정렬처럼 근본적으로 불연속적인 경우 딥러닝은 도움이 되지 않습니다. 따라서 적절한 데이터셋으로 작업하고 있는지 확인하는 것이 중요 합니다. 
- 데이터 수집에 노력과 비용을 투자한느 것이 동일한 노력과 비용을 모델 개발에 투자하는 것보다 거의 항상 더 나은 결과를 가져다줍니다. 
- 머신 러닝 모델의 목적은 이전에 본 적 없는 입력에서 정확하게 동작하는 일반화입니다.(보기보다 어렵습니다) 

---

- 사실 모델 개발은 머신 러닝 워플로의 한 단계에 불과하며 가장 어려운 단계도 아닙니다. 머신 러닝에서 가장 어려운 부분은 문제 정의와 데이터 수집, 애너테이션, 정제 입니다.

---

## 잔차 연결 

- 잔차 연결을 사용하면 그레이디언트 소실에 대해 걱정하지 않고 원하는 깊이의 네트워크를 만들 수 있습니다. 
- 케라스에 포함된 고급 컨브넷 구조는 배치 정규화를 많이 사용합니다. 여기에는 ResNet50, EfficientNet, Xception 등이 있습니다. 

---

## 깊이별 분리 합성곱

- 깊이별 분류 합성공은 중간 활성화에 있는 `공간상의 위치`가 `높은 상관관계`를 가지지만 채널 간에는 `매우 독립적`이라는 가정에 의존합니다. 


---

## 시계열을 위한 딥런이

- 이상치 탐지는 일반적으로 비지도 학습(unsupervised learning)으로 수행됩니다. 어떤 종류의 이상치를 찾는지 모르는 경우가 많아 구체적인 이상치 샘플로 훈련할 수 없기 때문입니다. 

---

## 생성 모델을 위한 딥러닝

- 시퀀스 데이터 생성(글을 쓰거나 작곡할 수 있습니다)과 딥드림, 변이형 오토인코더, 생성적 적대 신경망(generative adversarial network)을 사용한 이미지 생성.

---

- 딥러닝은 머신러닝의 여러 종류 중 하나입니다. 기하학적 변환 함수들이 번갈아 가며 연속적으로 길게 연결된 모델입니다. 이 연산들은 `층`이란 모듈을 구성합니다. 층은 훈련하는 동안 학습되는 `가중치` 파라미터를 가집니다. 이 가중치에 모델의 지식이 저장됩니다. 학습과정은 손실 함수를 최소화하는 좋은 가중치 값을 찾는 것입니다. 기하학적 변환의 연결이 미분가능하다면 `손실 함수`를 최소화하기 위해 `경사 하강법`으로 가중치를 효율적으로 업데이트 할 수 있습니다.
- 매우 깊은 컨브넷을 만들 때 `배치 정규화` 층과 `잔차 연결`을 추가한느 것이 일반적입니다. 이 두 아키텍처 패턴은 그레이디언트 정보가 네트워크를 잘 통과해서 흐르도록 돕습니다. 


....작성중